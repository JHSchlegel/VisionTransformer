data:
  dataset: 'cifar10' # 'cifar10' or 'cifar100'
  train_batch_size: 128 # batch size for training
  val_batch_size: 512 # batch size for validation
  test_batch_size: 512 # batch size for testing
  val_perc_size: 0.2 # percentage of training data to use for validation

model:
  input_channels: 3          # input channels 
  initial_filters: 16        # Number of filters in the first convolutional layer
  block_configs:             # Configuration for residual layers
    - [2, 32, 1]             # Layer 1: 2 blocks, 32 filters, stride 1
    - [3, 64, 2]             # Layer 2: 3 blocks, 64 filters, stride 2
    - [4, 128, 2]            # Layer 3: 4 blocks, 128 filters, stride 2

training:
  num_epochs: 200 # number of training epochs
  use_early_stopping: True # whether to use early stopping
  early_stopping_patience: 10 # patience for early stopping
  early_stopping_tol: 1e-7 # tolerance for early stopping
  save_model_every: 1 # checkpoint frequency
  use_wandb: True # whether to use Weights & Biases
  wandb_project: 'vit' # Weights & Biases project name
  num_samples: 5 # number of samples to visualize
  top_k: 5 # number of top-k predictions to visualize

optimizer:
  lr: 0.0003 # learning rate
  weight_decay: 0.0001 # weight decay

scheduler:
  T_0: 10 # number of iterations for the first cycle
  T_mult: 2 # factor by which the cycle length (initially T_0) is increased after each cycle

hydra:
  run:
    dir: '../results/resnet/${data.dataset}'